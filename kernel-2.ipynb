{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport glob\nimport cv2\nimport torch\nimport torch.nn as nn\n\n# from torchstat import stat\nimport glob\nimport torch.optim as optim\n\n\nimport os\nprint(os.listdir(\"../input/train/\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['masks', 'images']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b5f0ce2ae13b08c4ca5c594d81fc7f666c65851a"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nimport torch\nimport torch.nn as nn\n\nclass UNet_down_block(torch.nn.Module):\n    def __init__(self, input_channel, output_channel, down_size):\n        super(UNet_down_block, self).__init__()\n        self.conv1 = torch.nn.Conv2d(input_channel, output_channel, 3, padding=1)\n        self.bn1 = torch.nn.BatchNorm2d(output_channel)\n        self.conv2 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn2 = torch.nn.BatchNorm2d(output_channel)\n        self.conv3 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn3 = torch.nn.BatchNorm2d(output_channel)\n        self.max_pool = torch.nn.MaxPool2d(2, 2)\n        self.relu = torch.nn.ReLU()\n        self.down_size = down_size\n\n    def forward(self, x):\n        if self.down_size:\n            x = self.max_pool(x)\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.relu(self.bn2(self.conv2(x)))\n        x = self.relu(self.bn3(self.conv3(x)))\n        return x\n\nclass UNet_up_block(torch.nn.Module):\n    def __init__(self, prev_channel, input_channel, output_channel):\n        super(UNet_up_block, self).__init__()\n        self.up_sampling = torch.nn.Upsample(scale_factor=2, mode='bilinear')\n        self.conv1 = torch.nn.Conv2d(input_channel + input_channel, output_channel, 3, padding=1)\n        self.bn1 = torch.nn.BatchNorm2d(output_channel)\n        self.conv2 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn2 = torch.nn.BatchNorm2d(output_channel)\n        self.conv3 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn3 = torch.nn.BatchNorm2d(output_channel)\n        self.relu = torch.nn.ReLU()\n        \n#         self.up1=torch.nn.ConvTranspose2d(12,25,3,stride=2,padding=1)\n\n    def forward(self, prev_feature_map, x,k):\n#         print('before up',x.size())\n        if k!=0:\n            x = self.up_sampling(x)\n        x = torch.cat((x, prev_feature_map), dim=1)\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.relu(self.bn2(self.conv2(x)))\n        x = self.relu(self.bn3(self.conv3(x)))\n        return x\n\n\nclass UNet(torch.nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n\n        self.down_block1 = UNet_down_block(3, 16, False)\n        self.down_block2 = UNet_down_block(16, 32, True)\n        self.down_block3 = UNet_down_block(32, 64, True)\n        \n        self.mid_conv1 = torch.nn.Conv2d(64, 64, 3, padding=1)\n        self.bn1 = torch.nn.BatchNorm2d(64)\n        self.mid_conv2 = torch.nn.Conv2d(64, 64, 3, padding=1)\n        self.bn2 = torch.nn.BatchNorm2d(64)\n        self.mid_conv3 = torch.nn.Conv2d(64, 64, 3, padding=1)\n        self.bn3 = torch.nn.BatchNorm2d(64)\n\n        self.up_block5 = UNet_up_block(32, 64, 32)\n        self.up_block6 = UNet_up_block(16, 32, 16)\n        self.up_block7 = UNet_up_block(3, 16, 16)\n\n        self.last_conv1 = torch.nn.Conv2d(16, 3, 3, padding=1)\n        self.last_bn = torch.nn.BatchNorm2d(3)\n        self.last_conv2 = torch.nn.Conv2d(3, 2, 1, padding=0)\n        self.relu = torch.nn.ReLU()\n        \n        self.max_pool = torch.nn.MaxPool2d(2, 2)\n\n    def forward(self, x):\n#         ins=x.clone()\n        self.x1 = self.down_block1(x)\n#         print('self.x1',self.x1.size())\n        self.x2 = self.down_block2(self.x1)\n#         print('self.x2',self.x2.size())\n        self.x3 = self.down_block3(self.x2)\n#         print('self.x3',self.x3.size())\n         \n#         self.mid=self.max_pool(self.x3)    \n \n\n        self.x7 = self.relu(self.bn1(self.mid_conv1(self.x3)))\n        self.x7 = self.relu(self.bn2(self.mid_conv2(self.x7)))\n        self.x7 = self.relu(self.bn3(self.mid_conv3(self.x7)))\n        \n#         print('prev,x',self.x7.size(),self.x3.size())\n        \n        x = self.up_block5(self.x3, self.x7,k=0)\n#         print('self.x',x.size())\n        x = self.up_block6(self.x2, x,k=1)\n#         print('6',x.size())\n        \n        x=self.up_block7(self.x1,x,k=1)\n#         print('7',x.size())\n        x = self.relu(self.last_bn(self.last_conv1(x)))\n        x = self.last_conv2(x)\n#         print(' out',x.size())\n        return x\ndef standard(x):\n    mean=np.mean(x)\n    \n    return((x-mean)/np.std(x))\n\n\nclass DatasetSalt(Dataset):\n    \n    def __init__(self, file_path='../input/train/images/*', transform=None,limit_paths=len(glob.glob('../input/train/images/*'))):\n        self.path = glob.glob(file_path)\n        \n        self.path=self.path[:limit_paths]\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.path)\n    \n    def __getitem__(self, index):\n        \n        images = cv2.imread(self.path[index])\n        images=images[:-1,:-1,:]\n        \n        images=standard(images)\n        \n        images=torch.from_numpy(images)\n        images.transpose_(1,2)\n        images.transpose_(0,1)\n        \n        \n        \n        mks='../input/train/masks/'+self.path[index][len('../input/train/images/'):]\n        \n        labels=cv2.imread(mks)[:-1,:-1,0]\n        \n        labels=labels/255\n        \n\n        \n        sample={'image': images,'label': torch.from_numpy(labels)}\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return sample\n\n\n# def dice(input, target,weights=torch.tensor([0.9,0.1]).cuda()):\n#     smooth=.001\n#     input=input.view(-1)\n#     target=target.view(-1)\n    \n#     #create opp labels\n#     target2=1-target\n#     input2=1-input\n    \n#     score1=2*(input*target).sum()/(input.sum()+target.sum()+smooth) #1s orig\n#     score2=2*(input2*target2).sum()/(input2.sum()+target2.sum()+smooth) #0's orig\n    \n    \n#     score=1-(weights[0]*score1+weights[1]*score2)/2\n#     if score<0:\n#         score=score-score\n    \n#     return(score)\n  \n",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "61658def7eab61a89002a5f7e24dad1353becf43"
      },
      "cell_type": "code",
      "source": "\ndef dice(input, target,weights=torch.tensor([1,1]).float().cuda()):\n    smooth=.001\n    \n    dummy=np.zeros([batch_size,2,100,100]) # create dummy to one hot encode target for weighted dice\n    dummy[:,0,:,:][target==0]=1 # background class is 0\n    dummy[:,1,:,:][target==1]=1 # salt class is 1 \n    \n    \n    target=torch.tensor(dummy).float().cuda()\n    \n#     print(input.size(),input[:,0,:,:].size())\n    input1=input[:,0,:,:].contiguous().view(-1) #flatten both classes seperately\n    target1=target[:,0,:,:].contiguous().view(-1)\n    \n    input2=input[:,1,:,:].contiguous().view(-1)\n    target2=target[:,1,:,:].contiguous().view(-1)\n    \n    score1=2*(input1*target1).sum()/(input1.sum()+target1.sum()+smooth) #back\n    score2=2*(input2*target2).sum()/(input2.sum()+target2.sum()+smooth) #salt\n\n    \n    score=1-(weights[0]*score1+weights[1]*score2)/2\n    if score<0:\n        score=score-score\n    \n    return(score)\n  ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bf0f01f69132680cc5da6a0698c150096c0329f2"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8242e10acf68b76143447a6657fa93f2450c2ab5"
      },
      "cell_type": "code",
      "source": "soft_max=torch.nn.Softmax(dim=1)\n\ndef train(epoch):\n    for idx, batch_data in enumerate(dataloader) : \n        x, target=batch_data['image'].float().cuda(),batch_data['label'].float().cuda()\n\n\n        optimizer.zero_grad()\n        output = net(x)\n#         print(output.size())\n        output.squeeze_(1)\n\n#         print('out',output.size(),target.size())\n        bce_loss = criterion(output, target.long())\n        lc.append(bce_loss.item())\n\n        dice_loss = dice((output), target)\n        ld.append(dice_loss.item())\n        loss =  dice_loss + bce_loss\n        l.append(loss.item())\n\n        loss.backward()\n        optimizer.step()\n\n        print('Epoch {}, loss {}, bce {}, dice {}'.format(\n            epoch, sum(l)/len(l), sum(lc)/len(lc) , sum(ld)/len(ld) ))\n\n\n",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "325b67b8b288040afb9d1ac6df33ddbefefd1966"
      },
      "cell_type": "code",
      "source": "      \nbatch_size=10\n \nnet = UNet().cuda()\n\noptimizer = torch.optim.SGD(net.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss(weight=torch.tensor([0.3,0.7]).cuda())\n\n\ndataset=DatasetSalt(limit_paths=10)\ndataloader=DataLoader(dataset,batch_size, shuffle=True, num_workers=2)\n",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "59be450f4c3ba2762afd2d65b6ec6a81ca5dde06"
      },
      "cell_type": "code",
      "source": "\nld=[]\nlc=[]\nl=[]\noptimizer = torch.optim.Adam(net.parameters(), lr=0.005)\n\n\nfor epoch in range(1000):train(epoch)",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 0, loss 1.6740732735141794, bce 0.5723414310702571, dice 1.101587417911976\nEpoch 1, loss 1.673726949426863, bce 0.5722778841068871, dice 1.10130574148168\nEpoch 2, loss 1.6741589455228103, bce 0.5721294614657058, dice 1.1018876960403041\nEpoch 3, loss 1.6718351188754537, bce 0.5719691052411994, dice 1.09972580721241\nEpoch 4, loss 1.6697585020835202, bce 0.5718008137737531, dice 1.0978190889582038\nEpoch 5, loss 1.6689814344588956, bce 0.5716339908924299, dice 1.0972104270223508\nEpoch 6, loss 1.6680556520358802, bce 0.57146424024533, dice 1.0964559768278574\nEpoch 7, loss 1.6668659855157901, bce 0.5712926083681534, dice 1.0954395168866866\nEpoch 8, loss 1.6669372657732087, bce 0.5711305861545698, dice 1.095674328962151\nEpoch 9, loss 1.666284695192037, bce 0.5709703838584399, dice 1.0951834460200391\nEpoch 10, loss 1.6652938184714077, bce 0.5708102712679148, dice 1.094354151475309\nEpoch 11, loss 1.66402554541976, bce 0.5706528002023696, dice 1.0932447910308838\nEpoch 12, loss 1.6632032707333564, bce 0.5704846909983241, dice 1.0925921058654786\nEpoch 13, loss 1.6617888867558532, bce 0.5703233996830365, dice 1.0913404448708492\nEpoch 14, loss 1.6608754074809575, bce 0.5701625294286042, dice 1.0905892509635131\nEpoch 15, loss 1.6593824939187525, bce 0.5699972355482625, dice 1.0892630545376556\nEpoch 16, loss 1.6581731838922875, bce 0.5698252927966234, dice 1.0882271288656722\nEpoch 17, loss 1.6567840172023307, bce 0.5696460824568295, dice 1.0870186357963376\nEpoch 18, loss 1.6552738498136834, bce 0.5694644491453678, dice 1.0856915625553687\nEpoch 19, loss 1.6538408980277426, bce 0.569290113563721, dice 1.0844343581061433\nEpoch 20, loss 1.6523289408248205, bce 0.5691253425972314, dice 1.0830885237799242\nEpoch 21, loss 1.6502300286977485, bce 0.5689627108119782, dice 1.0811535721760617\nEpoch 22, loss 1.6487873085907527, bce 0.5687938502049559, dice 1.0798810587042853\nEpoch 23, loss 1.6474267620045993, bce 0.5686244481014755, dice 1.078691249492609\nEpoch 24, loss 1.6459916529228102, bce 0.5684558500146641, dice 1.0774260576603547\nEpoch 25, loss 1.64405593877667, bce 0.5682846082148151, dice 1.0756629047819146\nEpoch 26, loss 1.642332371985801, bce 0.5681252393611642, dice 1.074099958221489\nEpoch 27, loss 1.640694746583007, bce 0.5680183837259257, dice 1.0725701842197153\nEpoch 28, loss 1.6391998057564099, bce 0.5678904979459701, dice 1.0712042128046353\nEpoch 29, loss 1.6374809294252353, bce 0.567741596370662, dice 1.0696354085399258\nEpoch 30, loss 1.635735222232451, bce 0.5675756770726208, dice 1.0680568584608376\nEpoch 31, loss 1.6338440558137415, bce 0.5673958645625548, dice 1.0663467945029201\nEpoch 32, loss 1.6321347618644888, bce 0.5672109809396494, dice 1.0648236854509874\nEpoch 33, loss 1.630486013393057, bce 0.5670323245697193, dice 1.0633548546700455\nEpoch 34, loss 1.6290385876152966, bce 0.5668646770742441, dice 1.0620762767555478\nEpoch 35, loss 1.6275251919378615, bce 0.5666991788893938, dice 1.0607295589596701\nEpoch 36, loss 1.626537614901151, bce 0.5665329141087002, dice 1.059909419289657\nEpoch 37, loss 1.6246012086338466, bce 0.5663653092574229, dice 1.0581417859925164\nEpoch 38, loss 1.6228674051508438, bce 0.5661953734931442, dice 1.0565790863691178\nEpoch 39, loss 1.6209353956882124, bce 0.5660220876074674, dice 1.0548215356167192\nEpoch 40, loss 1.619152845782146, bce 0.5658453708132282, dice 1.0532168798279344\nEpoch 41, loss 1.617835338719547, bce 0.565667814793794, dice 1.0520780997505355\nEpoch 42, loss 1.6168451394723808, bce 0.5654927435375395, dice 1.05126412148061\nEpoch 43, loss 1.6153649914832342, bce 0.5653189392439251, dice 1.0499589125831406\nEpoch 44, loss 1.613392737148137, bce 0.5651495587160659, dice 1.0481571444663509\nEpoch 45, loss 1.6121167121015394, bce 0.5649862544149415, dice 1.0470454938421945\nEpoch 46, loss 1.6102138408738325, bce 0.5648199999586064, dice 1.0453099503985837\nEpoch 47, loss 1.6089892861690926, bce 0.564648076639337, dice 1.0442584073289911\nEpoch 48, loss 1.6079501648575574, bce 0.5644608051968023, dice 1.043407702092397\nEpoch 49, loss 1.6059832027189842, bce 0.5642631186657593, dice 1.0416396054034496\nEpoch 50, loss 1.6044887301801634, bce 0.5640559874817916, dice 1.0403534722428363\nEpoch 51, loss 1.6026063102558568, bce 0.5638417169451714, dice 1.038686551060138\nEpoch 52, loss 1.6008719963332017, bce 0.5636184982244404, dice 1.0371767111122607\nEpoch 53, loss 1.5989491298980238, bce 0.5633865905202124, dice 1.0354870332721853\nEpoch 54, loss 1.5975623010111248, bce 0.5631474379158805, dice 1.0343406572322216\nEpoch 55, loss 1.5957863092913058, bce 0.562903282583737, dice 1.0328101312182076\nEpoch 56, loss 1.5938607617968419, bce 0.5626564497850379, dice 1.0311327268842791\nEpoch 57, loss 1.5923106765260502, bce 0.5624092352099535, dice 1.0298311574118477\nEpoch 58, loss 1.5907528296234161, bce 0.5621621596668414, dice 1.0285216761313802\nEpoch 59, loss 1.5887583250458908, bce 0.5619146117279606, dice 1.0267760012796534\nEpoch 60, loss 1.5874968447512197, bce 0.5616645380914451, dice 1.025765875895177\nEpoch 61, loss 1.5856732539383762, bce 0.5614110410213471, dice 1.0241970671228615\nEpoch 62, loss 1.5843993561267853, bce 0.561153678780058, dice 1.0231818218231201\nEpoch 63, loss 1.5824949924214429, bce 0.5608937713125396, dice 1.0215386555964254\nEpoch 64, loss 1.580928657026518, bce 0.5606322706688063, dice 1.0202351065855177\nEpoch 65, loss 1.5795376034593394, bce 0.5603686511281907, dice 1.019108956745962\nEpoch 66, loss 1.578496303380005, bce 0.5601016849863762, dice 1.0183359100593357\nEpoch 67, loss 1.577090491734299, bce 0.5598323183367029, dice 1.017200751398124\nEpoch 68, loss 1.5756577558349818, bce 0.5595607104700363, dice 1.016040908638388\nEpoch 69, loss 1.5744783797152775, bce 0.559285449080689, dice 1.0151380833948633\nEpoch 70, loss 1.573581576578377, bce 0.5590074246454423, dice 1.014520594777987\nEpoch 71, loss 1.572482117124506, bce 0.5587253861702406, dice 1.0137044695353417\nEpoch 72, loss 1.5710147869128448, bce 0.5584382748238428, dice 1.0125255559499446\nEpoch 73, loss 1.5696273035016552, bce 0.5581469982862473, dice 1.0114306601984748\nEpoch 74, loss 1.5682024539426993, bce 0.5578554787110013, dice 1.0102986322559473\nEpoch 75, loss 1.5666271799417504, bce 0.5575692001165766, dice 1.0090109089481514\nEpoch 76, loss 1.5653473312656085, bce 0.5572850288085218, dice 1.0080164862853107\nEpoch 77, loss 1.5636944692089874, bce 0.5570051612934672, dice 1.0066447208512503\nEpoch 78, loss 1.5623693558058345, bce 0.5567101243506657, dice 1.005615920948803\nEpoch 79, loss 1.5615638898553026, bce 0.5564033543663238, dice 1.0051185361454995\nEpoch 80, loss 1.5605003048679722, bce 0.5561125357133305, dice 1.0043470114469528\nEpoch 81, loss 1.5590226572685526, bce 0.55582415163517, dice 1.0031589715011058\nEpoch 82, loss 1.5573661466439566, bce 0.5555632902907269, dice 1.0017644347967924\nEpoch 83, loss 1.556139170683618, bce 0.5553080732112422, dice 1.0007937594533407\nEpoch 84, loss 1.5550089835682337, bce 0.5550328532418052, dice 0.9999399413080776\nEpoch 85, loss 1.553395621287517, bce 0.5547254257393579, dice 0.9986352654167148\nEpoch 86, loss 1.5522721359764573, bce 0.5543891906738281, dice 0.9978493700062272\nEpoch 87, loss 1.5507513954422691, bce 0.5540535668100136, dice 0.9966655960949985\nEpoch 88, loss 1.5493956758924152, bce 0.5537285749877834, dice 0.9956361627665119\nEpoch 89, loss 1.5483483237479998, bce 0.553405920056988, dice 0.9949127420621658\nEpoch 90, loss 1.5470836876536445, bce 0.5530849189954846, dice 0.9939703686203031\nEpoch 91, loss 1.5455053294858625, bce 0.5527625458581107, dice 0.9927156409482375\nEpoch 92, loss 1.5444135744656835, bce 0.5524392276472044, dice 0.991948455785002\nEpoch 93, loss 1.5429722777040829, bce 0.5521151794398085, dice 0.9908324524601159\nEpoch 94, loss 1.5420732952601521, bce 0.5517915235601971, dice 0.9902583607967864\nEpoch 95, loss 1.5411418729030624, bce 0.5514708133020871, dice 0.9896488644630244\nEpoch 96, loss 1.5397879416254205, bce 0.5511548717816671, dice 0.9886120652229013\nEpoch 97, loss 1.5380377884496723, bce 0.5508446895576024, dice 0.9871732563303228\nEpoch 98, loss 1.5362410334857193, bce 0.5505412971724201, dice 0.9856810238394704\nEpoch 99, loss 1.5346314884228989, bce 0.5502474849215813, dice 0.9843663799638117\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Epoch 100, loss 1.5334535110741854, bce 0.5499599117102507, dice 0.9834770355373621\nEpoch 101, loss 1.5322406174402337, bce 0.5496760324157518, dice 0.9825490607934839\nEpoch 102, loss 1.530980877013042, bce 0.5493973187359747, dice 0.9815690488650881\nEpoch 103, loss 1.5293453053100823, bce 0.5491177790785489, dice 0.9802140271950424\nEpoch 104, loss 1.5279491917319494, bce 0.5488276532485623, dice 0.9791090792580827\nEpoch 105, loss 1.5266972615450316, bce 0.5485295209349418, dice 0.9781563414241674\nEpoch 106, loss 1.524859142749488, bce 0.5482127984701577, dice 0.9766360610520759\nEpoch 107, loss 1.522915550005638, bce 0.5478711658837022, dice 0.9750352938296432\nEpoch 108, loss 1.5216360599608034, bce 0.5475322249963227, dice 0.9740959206545675\nEpoch 109, loss 1.520410464267538, bce 0.5471967921761058, dice 0.9732069138324622\nEpoch 110, loss 1.5192385587916277, bce 0.5468506728326995, dice 0.9723823116529708\nEpoch 111, loss 1.5178153203881306, bce 0.5465058178702991, dice 0.971305100216116\nEpoch 112, loss 1.5160041445493697, bce 0.5461500789041931, dice 0.9698508638143539\nEpoch 113, loss 1.5148281288701435, bce 0.5457905692769992, dice 0.9690355626847657\nEpoch 114, loss 1.5135401544586713, bce 0.545417313135103, dice 0.9681220869749587\nEpoch 115, loss 1.51242863797512, bce 0.5450369842154416, dice 0.9673921572099818\nEpoch 116, loss 1.5114442033595161, bce 0.5446617765504805, dice 0.9667841629370263\nEpoch 117, loss 1.5105629575057107, bce 0.5443093302397947, dice 0.9662565131656459\nEpoch 118, loss 1.5091752567711998, bce 0.5439848325151574, dice 0.9651943610774146\nEpoch 119, loss 1.5080674647896608, bce 0.5436350505847436, dice 0.9644374775575892\nEpoch 120, loss 1.507190080238627, bce 0.5432132285775491, dice 0.9639832683197864\nEpoch 121, loss 1.506294748351026, bce 0.5427931291441763, dice 0.963509374644764\nEpoch 122, loss 1.505284171911978, bce 0.5423765887784805, dice 0.9629166570401961\nEpoch 123, loss 1.5039956594586756, bce 0.5419590416818093, dice 0.9620470051980096\nEpoch 124, loss 1.502849665398781, bce 0.5415226909489678, dice 0.9613387269469408\nEpoch 125, loss 1.5013477922247622, bce 0.5410857796669006, dice 0.9602751234849802\nEpoch 126, loss 1.4997118047088573, bce 0.5406616016039772, dice 0.9590646231630046\nEpoch 127, loss 1.498563779724969, bce 0.5402614014058174, dice 0.958318022886912\nEpoch 128, loss 1.4969940332672265, bce 0.5398879955619668, dice 0.957122814240335\nEpoch 129, loss 1.4959174650324631, bce 0.5394933080335833, dice 0.9564421257762127\nEpoch 130, loss 1.4942941637534015, bce 0.5390892922878265, dice 0.9552240542270852\nEpoch 131, loss 1.4929855974116668, bce 0.5386821620166302, dice 0.9543238343863651\nEpoch 132, loss 1.4913170808926224, bce 0.5382720191159353, dice 0.9530666787177324\nEpoch 133, loss 1.49010279301171, bce 0.5378589221039174, dice 0.9522667074129217\nEpoch 134, loss 1.4893139454518787, bce 0.5374278861671778, dice 0.9519101634899282\nEpoch 135, loss 1.4882959096055282, bce 0.5369960042981454, dice 0.9513252720744249\nEpoch 136, loss 1.4869021639043902, bce 0.5365608279521649, dice 0.9503679674716643\nEpoch 137, loss 1.4855923973597014, bce 0.536126061634052, dice 0.9494942232278677\nEpoch 138, loss 1.4839732016156788, bce 0.5356843744031515, dice 0.9483179839476485\nEpoch 139, loss 1.4828387712119917, bce 0.5352405590436807, dice 0.9476286367903427\nEpoch 140, loss 1.4813196704518505, bce 0.5348043275096859, dice 0.9465470048712521\nEpoch 141, loss 1.4796487612927214, bce 0.5343968783364151, dice 0.9452846870958624\nEpoch 142, loss 1.4783982495466867, bce 0.5340009360515099, dice 0.9444312180533554\nEpoch 143, loss 1.4774125373255451, bce 0.5336061668503715, dice 0.9438413651688221\nEpoch 144, loss 1.4757374013403812, bce 0.5331902090493623, dice 0.9425833345536726\nEpoch 145, loss 1.4747648645449687, bce 0.5327649384201644, dice 0.9420372369411113\nEpoch 146, loss 1.4736905874249464, bce 0.5323326630378837, dice 0.9413964177320103\nEpoch 147, loss 1.4720252892864285, bce 0.5318955172385488, dice 0.9401694554001537\nEpoch 148, loss 1.4707711837476207, bce 0.5314578189340473, dice 0.939354232734158\nEpoch 149, loss 1.4692368827517026, bce 0.5310191321655138, dice 0.938259798978132\nEpoch 150, loss 1.4675922769413898, bce 0.5305776994312759, dice 0.9370578076007098\nEpoch 151, loss 1.4661520010953808, bce 0.5301299731521045, dice 0.9360664513258807\nEpoch 152, loss 1.4646863677922417, bce 0.5296777374933193, dice 0.9350542531293982\nEpoch 153, loss 1.4631595709456726, bce 0.5292179022441831, dice 0.9339885061437433\nEpoch 154, loss 1.4620001988801343, bce 0.5287546114045747, dice 0.933293642704947\nEpoch 155, loss 1.4607368474799065, bce 0.5282911627098571, dice 0.9324949510591023\nEpoch 156, loss 1.4592835740294567, bce 0.5278302293756734, dice 0.9315038077359976\nEpoch 157, loss 1.4577014273491458, bce 0.5273776612529865, dice 0.9303753946138464\nEpoch 158, loss 1.4566463459433847, bce 0.5269319287122842, dice 0.9297671846916221\nEpoch 159, loss 1.4550084088652553, bce 0.5264766473194649, dice 0.9285856890747114\nEpoch 160, loss 1.4537579180865452, bce 0.5260171041447659, dice 0.9277959068616232\nEpoch 161, loss 1.4531131753948834, bce 0.5255535621302468, dice 0.9276158765257259\nEpoch 162, loss 1.452125301361084, bce 0.5250768203001756, dice 0.9271059458596366\nEpoch 163, loss 1.4510932641151624, bce 0.5245887290009044, dice 0.9265632265992993\nEpoch 164, loss 1.4500536820427938, bce 0.5241011069617934, dice 0.9260124850340865\nEpoch 165, loss 1.4485622995635943, bce 0.5236164624408141, dice 0.9250069502055138\nEpoch 166, loss 1.4476162986566792, bce 0.5231295586471826, dice 0.9245490559750358\nEpoch 167, loss 1.4460087393371153, bce 0.522637098023061, dice 0.9234351688707378\nEpoch 168, loss 1.4445518926623162, bce 0.5221424717195228, dice 0.9224741594510132\nEpoch 169, loss 1.4433480653108335, bce 0.5216418847691413, dice 0.9217721400808554\nEpoch 170, loss 1.4422946460753179, bce 0.5211396254702862, dice 0.9212221989418541\nEpoch 171, loss 1.440877059542037, bce 0.5206371217138237, dice 0.9203083287706614\nEpoch 172, loss 1.4393484074208471, bce 0.5201240804386932, dice 0.9192939531471994\nEpoch 173, loss 1.4381171535917265, bce 0.5196098630105593, dice 0.918578148383513\nEpoch 174, loss 1.4369090411873813, bce 0.5190973926345835, dice 0.9178837262793799\nEpoch 175, loss 1.435860932530122, bce 0.518584803729267, dice 0.9173494201389555\nEpoch 176, loss 1.4342882990182102, bce 0.5180707531432583, dice 0.9162920480901069\nEpoch 177, loss 1.43315087148588, bce 0.5175602120942757, dice 0.9156663561520512\nEpoch 178, loss 1.4317539795174625, bce 0.5170513423164794, dice 0.9147795174942642\nEpoch 179, loss 1.430202749671988, bce 0.5165355305956758, dice 0.9137452954492387\nEpoch 180, loss 1.4291187390361144, bce 0.5160178320840768, dice 0.9131801779503408\nEpoch 181, loss 1.4276158778971126, bce 0.5154962015313072, dice 0.9122001462512546\nEpoch 182, loss 1.4265171213729961, bce 0.5149732388736745, dice 0.9116255483111819\nEpoch 183, loss 1.4254323403147675, bce 0.5144498006951425, dice 0.9110653962729112\nEpoch 184, loss 1.4247912958424578, bce 0.5139267051507577, dice 0.9109486307828657\nEpoch 185, loss 1.4232717805189996, bce 0.5134021021465567, dice 0.9099548995974236\nEpoch 186, loss 1.42217364524775, bce 0.5128732478618622, dice 0.9093868047158349\nEpoch 187, loss 1.421096738656362, bce 0.512346495973303, dice 0.908837824344635\nEpoch 188, loss 1.4203775393518996, bce 0.5118048757868041, dice 0.9086614528552015\nEpoch 189, loss 1.4195607184415155, bce 0.5112647023938951, dice 0.9083860028011413\nEpoch 190, loss 1.418429976575589, bce 0.5107181260956938, dice 0.9078030450634225\nEpoch 191, loss 1.4170515630050196, bce 0.5101612527119486, dice 0.9069827335805566\nEpoch 192, loss 1.4156305576625623, bce 0.509592139971225, dice 0.9061320954247525\nEpoch 193, loss 1.4143142720532855, bce 0.5090222071602707, dice 0.9053869926397569\nEpoch 194, loss 1.4128855083001222, bce 0.5084514466962988, dice 0.9045302349859508\nEpoch 195, loss 1.411463238396159, bce 0.5078803662521144, dice 0.9036802854923915\nEpoch 196, loss 1.4101693785438936, bce 0.507322063384118, dice 0.9029459287412465\nEpoch 197, loss 1.408856427514708, bce 0.5067599495303445, dice 0.9021962955400541\nEpoch 198, loss 1.4075562427389807, bce 0.5061746323601528, dice 0.9014826857055407\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Epoch 199, loss 1.4068148100714968, bce 0.5055926872282913, dice 0.9013244408045629\nEpoch 200, loss 1.405753325248502, bce 0.5049972184825986, dice 0.900859695734437\nEpoch 201, loss 1.4043408411634, bce 0.5044018239547045, dice 0.9000438704588726\nEpoch 202, loss 1.4029883580330091, bce 0.5038108706016979, dice 0.8992835871684246\nEpoch 203, loss 1.4016699123260614, bce 0.5032243635125306, dice 0.8985528772139488\nEpoch 204, loss 1.40029654408596, bce 0.5026377429640627, dice 0.8977673522063664\nEpoch 205, loss 1.39891745919793, bce 0.5020526503850966, dice 0.896974572395247\nEpoch 206, loss 1.3978571772272816, bce 0.5014724974390826, dice 0.896495637252246\nEpoch 207, loss 1.3968007922172547, bce 0.5008957301727449, dice 0.8960171987738791\nEpoch 208, loss 1.395713636519933, bce 0.5003172780014106, dice 0.8955096728873976\nEpoch 209, loss 1.3946850802796313, bce 0.49973407956823035, dice 0.895065498592271\nEpoch 210, loss 1.393620306523002, bce 0.4991450402372164, dice 0.8945909564818569\nEpoch 211, loss 1.3923351086470717, bce 0.4985512655228376, dice 0.8939007316018107\nEpoch 212, loss 1.390971732735634, bce 0.4979553495410672, dice 0.8931344692409039\nEpoch 213, loss 1.3898790221559139, bce 0.49735720485300566, dice 0.8926411005029654\nEpoch 214, loss 1.3884984426830538, bce 0.49675671848706515, dice 0.8918622044188467\nEpoch 215, loss 1.3871664036592242, bce 0.49615493593829696, dice 0.8911331421684094\nEpoch 216, loss 1.3861149956684302, bce 0.4955522409927698, dice 0.8906856196941716\nEpoch 217, loss 1.3848435039873477, bce 0.4949489480315758, dice 0.8900186072161168\nEpoch 218, loss 1.3835702937812053, bce 0.49434561643026387, dice 0.8893499091047371\nEpoch 219, loss 1.3825347127726975, bce 0.4937357119485444, dice 0.8889254233468077\nEpoch 220, loss 1.3811797888255586, bce 0.4931193434958936, dice 0.8881880687732323\nEpoch 221, loss 1.3798689206829864, bce 0.49250131093147326, dice 0.8874964322029524\nEpoch 222, loss 1.3785218286805037, bce 0.4918767150736203, dice 0.8867751452980972\nEpoch 223, loss 1.3772381689136626, bce 0.4912632565619876, dice 0.886106120263863\nEpoch 224, loss 1.3762636008193192, bce 0.49065640189890136, dice 0.8857395612788432\nEpoch 225, loss 1.37552695614951, bce 0.4900445807095311, dice 0.8856158988239112\nEpoch 226, loss 1.3745129183294693, bce 0.4894184707877148, dice 0.8852291608202285\nEpoch 227, loss 1.373166732615735, bce 0.4887816753739921, dice 0.884520980392594\nEpoch 228, loss 1.3720278461965232, bce 0.48814361844417287, dice 0.8840213579913745\nEpoch 229, loss 1.3710111602604818, bce 0.487515963114905, dice 0.8836335036680281\nEpoch 230, loss 1.3697169925037183, bce 0.4868751295568835, dice 0.8829813716514259\nEpoch 231, loss 1.3686373139907182, bce 0.4862335722006503, dice 0.8825444486659011\nEpoch 232, loss 1.3673069978044146, bce 0.4856002046560731, dice 0.881848673025767\nEpoch 233, loss 1.3660099388867828, bce 0.48498119103117576, dice 0.8811717611027443\nEpoch 234, loss 1.3650319429370463, bce 0.48436501044471775, dice 0.8808110669890851\nEpoch 235, loss 1.3640086271802303, bce 0.4837405849599613, dice 0.8804133121567134\nEpoch 236, loss 1.3627622015071366, bce 0.4831109988338807, dice 0.8797976148297202\nEpoch 237, loss 1.3616386098020217, bce 0.48246585693157895, dice 0.8793203384736005\nEpoch 238, loss 1.360860460101159, bce 0.4818130940268693, dice 0.8791961374696992\nEpoch 239, loss 1.3595486623900277, bce 0.48116107678441244, dice 0.8785375355278301\nEpoch 240, loss 1.3584777739281966, bce 0.48051680850260187, dice 0.8781120703320637\nEpoch 241, loss 1.3571735425984666, bce 0.4798641507362211, dice 0.8774616658548653\nEpoch 242, loss 1.3558605515679647, bce 0.4792104862336493, dice 0.8768035054206849\nEpoch 243, loss 1.3547393075274756, bce 0.47855911559114855, dice 0.8763347872448631\nEpoch 244, loss 1.3534129491006885, bce 0.47790074131642973, dice 0.8756679692478092\nEpoch 245, loss 1.3524466583690247, bce 0.47723953995836493, dice 0.8753640471374741\nEpoch 246, loss 1.3511653148358869, bce 0.4765742482467629, dice 0.8747491666248867\nEpoch 247, loss 1.34984687553055, bce 0.4759081600387709, dice 0.8740979833164434\nEpoch 248, loss 1.3487917162956449, bce 0.475244600487792, dice 0.873707540264917\nEpoch 249, loss 1.3474736156398153, bce 0.47457537851105, dice 0.8730598258481146\nEpoch 250, loss 1.3461588945018645, bce 0.47390588792147015, dice 0.8724157548930547\nEpoch 251, loss 1.345041251807115, bce 0.47323708541013976, dice 0.8719680674526848\nEpoch 252, loss 1.344068005681038, bce 0.4725685663301658, dice 0.8716644872318614\nEpoch 253, loss 1.342754383476413, bce 0.47189886392646246, dice 0.8710217117722613\nEpoch 254, loss 1.3417371519550478, bce 0.4712282315602959, dice 0.8706762538506434\nEpoch 255, loss 1.3407206435774035, bce 0.4705562880850053, dice 0.8703328280900994\nEpoch 256, loss 1.339413781155337, bce 0.4698832295583875, dice 0.8697001606494457\nEpoch 257, loss 1.3381328051009875, bce 0.4692093173685095, dice 0.869094230083937\nEpoch 258, loss 1.3373044371070348, bce 0.46853485800142525, dice 0.8689414508674177\nEpoch 259, loss 1.3361887379780713, bce 0.467859665929739, dice 0.8685020697730232\nEpoch 260, loss 1.3351219998938697, bce 0.4671832548417068, dice 0.8681128665006587\nEpoch 261, loss 1.3338331269527597, bce 0.46650641408231525, dice 0.8675019539278706\nEpoch 262, loss 1.3328032913472918, bce 0.4658296896256259, dice 0.8671499571535323\nEpoch 263, loss 1.331731894328166, bce 0.46515270688496857, dice 0.8667566529134425\nEpoch 264, loss 1.3304521359701071, bce 0.4644746668225619, dice 0.866156042017768\nEpoch 265, loss 1.3291641863239785, bce 0.46379542281842967, dice 0.8655484416100626\nEpoch 266, loss 1.3280773944003992, bce 0.4631155499390193, dice 0.8651426242836772\nEpoch 267, loss 1.3267814984688393, bce 0.46243502869548503, dice 0.8645283478956957\nEpoch 268, loss 1.3254865528198712, bce 0.4617539418604494, dice 0.8639155838050341\nEpoch 269, loss 1.3246552678114476, bce 0.46107234480469506, dice 0.863766986901181\nEpoch 270, loss 1.3233900091013013, bce 0.4603899188810444, dice 0.863185242273922\nEpoch 271, loss 1.3223240336561515, bce 0.45970792355744733, dice 0.8628023445995805\nEpoch 272, loss 1.3210235525732454, bce 0.4590259727066354, dice 0.8621848920117254\nEpoch 273, loss 1.319936672674084, bce 0.45834243239520434, dice 0.8617826287761945\nEpoch 274, loss 1.3186606449998302, bce 0.45765902462453617, dice 0.8611910803751512\nEpoch 275, loss 1.3175441844159532, bce 0.45697635730150443, dice 0.8607583523569046\nEpoch 276, loss 1.316494205131613, bce 0.4562952853659148, dice 0.8603905021887401\nEpoch 277, loss 1.315223462991817, bce 0.4556124761316909, dice 0.859803625716958\nEpoch 278, loss 1.3139587479599555, bce 0.4549300374515052, dice 0.8592224004698413\nEpoch 279, loss 1.3126940884222567, bce 0.4542481999557752, dice 0.8586406236797635\nEpoch 280, loss 1.311822214951882, bce 0.4535669497589567, dice 0.8584510399999782\nEpoch 281, loss 1.3107285355962415, bce 0.45288584045273195, dice 0.8580395048106911\nEpoch 282, loss 1.3096731092067475, bce 0.4522049472590161, dice 0.8576660015481583\nEpoch 283, loss 1.3084082498418803, bce 0.4515248027835357, dice 0.8570823106289922\nEpoch 284, loss 1.307141168011447, bce 0.45084472082508037, dice 0.8564963302874969\nEpoch 285, loss 1.305904526287103, bce 0.45016467640420055, dice 0.8559407480927401\nEpoch 286, loss 1.3048408181103976, bce 0.44948503588375294, dice 0.8555576904413569\nEpoch 287, loss 1.3036100677440041, bce 0.4488052188598809, dice 0.855007763285386\nEpoch 288, loss 1.302514199198795, bce 0.4481254568327398, dice 0.8545926585167396\nEpoch 289, loss 1.3015560916384812, bce 0.44744714196755797, dice 0.8543138603994181\nEpoch 290, loss 1.3003007580046873, bce 0.44677078443927404, dice 0.8537358705219364\nEpoch 291, loss 1.2990453564299422, bce 0.446092352643609, dice 0.8531598871834343\nEpoch 292, loss 1.2980191979557276, bce 0.4454145050005457, dice 0.8528125575433175\nEpoch 293, loss 1.2970691926761873, bce 0.44473801162171167, dice 0.8525400198918618\nEpoch 294, loss 1.2958154805715647, bce 0.4440624389496649, dice 0.8519628488176592\nEpoch 295, loss 1.2945652143802209, bce 0.44338786218715603, dice 0.8513881216138046\nEpoch 296, loss 1.2933461572513107, bce 0.44271422850409736, dice 0.8508436544374987\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Epoch 297, loss 1.2921059457297177, bce 0.44204154558510445, dice 0.8502770763082602\nEpoch 298, loss 1.2911631764207847, bce 0.4413695720921307, dice 0.8500072255791951\nEpoch 299, loss 1.290196513982769, bce 0.4406984839283052, dice 0.8497125906621161\nEpoch 300, loss 1.2892294498007806, bce 0.4400280762334299, dice 0.849416868242084\nEpoch 301, loss 1.288170037703524, bce 0.43935872184074654, dice 0.8490277386150478\nEpoch 302, loss 1.2871075745748013, bce 0.4386900115583676, dice 0.8486349087588642\nEpoch 303, loss 1.2860485923508762, bce 0.43802234849975846, dice 0.8482445066912354\nEpoch 304, loss 1.2848274798654928, bce 0.4373572326849005, dice 0.8476894182887503\nEpoch 305, loss 1.2836299071930968, bce 0.43669223542577823, dice 0.8471577472183816\nEpoch 306, loss 1.2824310057076365, bce 0.43602586093575063, dice 0.8466261236773811\nEpoch 307, loss 1.2812115598206568, bce 0.4353608033289352, dice 0.8460726324958031\nEpoch 308, loss 1.2801583542698813, bce 0.43469762785633803, dice 0.8456834921192738\nEpoch 309, loss 1.2791094470551796, bce 0.4340358382337783, dice 0.8452972579050352\nEpoch 310, loss 1.2779115691003071, bce 0.4333749564741561, dice 0.844761139657124\nEpoch 311, loss 1.2767206299042175, bce 0.43271515126526355, dice 0.8442308779708847\nEpoch 312, loss 1.2755234506130217, bce 0.4320564155360896, dice 0.8436933010816574\nEpoch 313, loss 1.2745355111872128, bce 0.4313987487578297, dice 0.8433638895581106\nEpoch 314, loss 1.2736113369464874, bce 0.43074210395455126, dice 0.8430972157484031\nEpoch 315, loss 1.2724177714133595, bce 0.43008656572136617, dice 0.8425600384149116\nEpoch 316, loss 1.2714433126033298, bce 0.42943188093676427, dice 0.8422411093636165\nEpoch 317, loss 1.2702666771293867, bce 0.4287780373846825, dice 0.8417191573888949\nEpoch 318, loss 1.269075068442718, bce 0.42812480617321924, dice 0.8411816153601696\nEpoch 319, loss 1.2681508019595926, bce 0.42747274830233395, dice 0.8409102365110047\nEpoch 320, loss 1.266960525371897, bce 0.426822107892725, dice 0.8403714240535977\nEpoch 321, loss 1.2657926176292253, bce 0.4261729457945216, dice 0.8398534960034788\nEpoch 322, loss 1.2647915912609475, bce 0.4255252290232774, dice 0.8395009979313495\nEpoch 323, loss 1.2636265617060802, bce 0.42487880917906296, dice 0.8389831941188431\nEpoch 324, loss 1.2626790162175894, bce 0.42423364386456286, dice 0.8386816141428426\nEpoch 325, loss 1.2617657860817268, bce 0.42358888395797417, dice 0.8384139401870861\nEpoch 326, loss 1.26058002819347, bce 0.42294538359618883, dice 0.837872473414306\nEpoch 327, loss 1.2596701812975615, bce 0.42230285821092683, dice 0.8376059377077714\nEpoch 328, loss 1.2587070024983829, bce 0.42166178065353943, dice 0.8372846163751543\nEpoch 329, loss 1.2577893947263752, bce 0.4210220681769507, dice 0.837007495374698\nEpoch 330, loss 1.25678665297372, bce 0.42038334158172036, dice 0.8366442496482009\nEpoch 331, loss 1.2556199427974017, bce 0.4197454470854539, dice 0.8361161988594629\nEpoch 332, loss 1.2544698589123213, bce 0.4191091485936445, dice 0.8356031722747362\nEpoch 333, loss 1.2533199091561695, bce 0.4184745067580678, dice 0.8350886170557502\nEpoch 334, loss 1.2524349429141517, bce 0.41784142614493636, dice 0.8348374783536027\nEpoch 335, loss 1.2517486635175308, bce 0.41721054681271086, dice 0.8347828180794507\nEpoch 336, loss 1.2507835750588934, bce 0.41658161173264185, dice 0.8344473979855311\nEpoch 337, loss 1.249648947148096, bce 0.4159517648272188, dice 0.8339433491797674\nEpoch 338, loss 1.2486648805467802, bce 0.41532377570697887, dice 0.8335879976531851\nEpoch 339, loss 1.2477450880877659, bce 0.4146984980131189, dice 0.8332942009424575\nEpoch 340, loss 1.2467895899758195, bce 0.41407440847845745, dice 0.8329635053647287\nEpoch 341, loss 1.2459137562542646, bce 0.4134506877441451, dice 0.8327121020264797\nEpoch 342, loss 1.2447740656025006, bce 0.4128280775919697, dice 0.832195726430641\nEpoch 343, loss 1.24363559383457, bce 0.4122068161438954, dice 0.8316792157634728\nEpoch 344, loss 1.2427446200211245, bce 0.41158780907097275, dice 0.8314079418218225\nEpoch 345, loss 1.2418680688677317, bce 0.4109704367369971, dice 0.8311494501625619\nEpoch 346, loss 1.2409395009614108, bce 0.41035460537282104, dice 0.8308373953072766\nEpoch 347, loss 1.239848453642052, bce 0.4097400652939704, dice 0.8303615648055745\nEpoch 348, loss 1.2389721136484573, bce 0.4091263585194973, dice 0.830099604245442\nEpoch 349, loss 1.237853407637811, bce 0.40851393569136196, dice 0.8295939887702132\nEpoch 350, loss 1.2370039547021505, bce 0.40790330452744283, dice 0.8293558289348858\nEpoch 351, loss 1.2359198047632631, bce 0.4072931245935184, dice 0.8288825175315419\nEpoch 352, loss 1.2350412504540549, bce 0.4066843113787954, dice 0.828613430040854\nEpoch 353, loss 1.2341215223790096, bce 0.4060770769455776, dice 0.8283015847646815\nEpoch 354, loss 1.233018133583104, bce 0.4054712774866633, dice 0.8278046386708193\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Process Process-1287:\nProcess Process-1288:\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n    if not self._poll(timeout):\n  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n    if not self._poll(timeout):\n  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n    return self._poll(timeout)\n  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n    return self._poll(timeout)\n  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n    r = wait([self], timeout)\n  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n    ready = selector.select(timeout)\n  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n    r = wait([self], timeout)\n  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n    ready = selector.select(timeout)\n  File \"/opt/conda/lib/python3.6/selectors.py\", line 376, in select\n    fd_event_list = self._poll.poll(timeout)\n  File \"/opt/conda/lib/python3.6/selectors.py\", line 376, in select\n    fd_event_list = self._poll.poll(timeout)\nKeyboardInterrupt\nKeyboardInterrupt\nException ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f24264b46a0>>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 397, in __del__\n    def __del__(self):\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n    _error_if_any_worker_fails()\nRuntimeError: DataLoader worker (pid 4258) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-df8947a389b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-740f17ebe5b9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbce_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdice_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdice_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbce_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-d13bde386f61>\u001b[0m in \u001b[0;36mdice\u001b[0;34m(input, target, weights)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create dummy to one hot encode target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdummy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;31m# background class is 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdummy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;31m# salt class is 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "b3e31722dab89a7e9a27bfe683e2689f514d8826"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b737146da68fdcfb0a5ab6281c82bbd17cac4aad"
      },
      "cell_type": "code",
      "source": "plt.plot(ld)\nplt.show()\n\nplt.plot(lc)\nplt.show()",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl4VdW9//H3N3NCZgiBkDDJGEBAIoIjjgVU0Fot2jpVa6311l69rdjB3no73d7+1NpilaqtU+vYKnWoIuKEDIZ5EhLClABJCJlD5vX7I4c0YDQBTtg5J5/X85yHs/deOee7Hg4fVvZZe21zziEiIsElxOsCRETE/xTuIiJBSOEuIhKEFO4iIkFI4S4iEoQU7iIiQUjhLiIShBTuIiJBSOEuIhKEwrx64z59+rjBgwd79fYiIgFp5cqV+51zKR218yzcBw8eTHZ2tldvLyISkMxsZ2fa6bSMiEgQUriLiAQhhbuISBBSuIuIBKFOhbuZTTezLWaWa2ZzP6fNVWa2ycw2mtlf/VumiIgcjQ5ny5hZKDAPuBDIBz4xswXOuU1t2gwH7gHOcM6VmlnfripYREQ61pmR+2Qg1zmX55yrB54DZh/R5pvAPOdcKYBzrsi/ZYqIyNHoTLgPAHa32c737WtrBDDCzJaY2TIzm97eC5nZLWaWbWbZxcXFx1Twyp2l/O+/Pj2mnxUR6Sn89YVqGDAcmAZcDfzJzBKPbOScm++cy3LOZaWkdHiBVbs27innj+9tY8f+6uOpV0QkqHUm3AuAjDbb6b59beUDC5xzDc657cBWWsLe784Z0fKfwvtbj23kLyLSE3Qm3D8BhpvZEDOLAOYAC45o8woto3bMrA8tp2ny/Fhnq0G9e5GeFM2yvJKuePnPqKpr5NU1BeQVV52Q9xMR8YcOZ8s45xrN7HbgLSAUeMI5t9HM7gOynXMLfMcuMrNNQBPwfedcl6Xv+IxE1u4u66qXb9XY1Myc+UvZUFBBRGgIP798LFOG9GZg75guf28RkePRqYXDnHNvAG8cse/eNs8dcKfv0eXGDUjg9XV7Ka2uJ6lXRJe9z+vr97KhoIK5M0bx8sp8fvDSOkIMLjk5jbOG92F0/3gOVNdTWFHLvvJa8ksPkl9Ww77yWkqq66mqbSQmIpT0pBgGJEUzIDGa9KRDjxhGpMYREabryETE/zxbFfJ4TBqUBMCSbfvpnxBN37hIMpL9P5pesGYP6UnR3HLWUK6bOojsHaUs3lLE31cVsGDtns+0T4mLZEBiNCNS4+gTG0mvyDCq6hooKD3IzpJqPs7dT3V9U2v7qPAQTh2czEVj+vGlMan0jYvyex9EpGeylkH3iZeVleWOdcnfxqZmJty3kKq6xtZ94wYkkJ4Uzah+8YxLj2dEahxJMRHERIRiZkf9HrUNTUy8byFXZqVz3+yxhx1zzrF6dxlFFbUkxUTQLyGK1PgoosJDv/A1nXOUH2wgv/QgO0tq+GTHAT7YWkze/mrMYNLAJKaP7ceEjEQykmNIiY0kJOToaxeR4GVmK51zWR21C8iRe1hoCD+bNYaVu0pJT4rGOfgoZz9b9lXyr437aPv/VWJMOGcO68PEgUlcenJ/+sZ3bnScvaOUgw1NTBv52SmbZsYpA5OOum4zIzEmgsSYCMYOSODik/vjnCOnqIo31+/jXxv38fPXN7e2jwgLIT0pmoykmNZTOelJ0ZwzMoX4qPCjfn8R6TkCcuT+RarqGtlYUE7e/moqDjaQU1TFhznFFFbUEWJw5aQMvpKVzpi0eGIiwig/2MCesoM8tXQny7eXMG5AAqU1DWzfX0VhRR1r772I6IgvHpH70+4DNeQWV5F/oIbdpQfZfaCG/NKD7C6toaymAYDYyDBuOH0w3zxrKAkxCnmRnqSzI/egC/fPk1dcxZ+X7ODpZS03MQkxiI8Obw3MQ9ISomhodhRX1nHp+DR+f/XEE1ZjR6rqGtmyr5InPtrO6+v3EhcVxjfPGsqNZwwmTiN5kR5B4f45iivrWJdfxrr8coqr6hiUHENB2UGe/2Q3T9xwKmcM60NZTT1PL93J16cM6tLZOMdj894K7l+4lYWbCkmMCefWc07imtMG6nSNSJBTuPcQ6/LLuH/hVt7bUkx4qJGZlsBJKb0Y1jeW0f3iOWVgkk7diAQRhXsPsy6/zDcvv5xtRdXsq6gFwAxG9YtnytBkpgztzWlDkkmM6Z6/jYhIxxTuPVxFbQMbCsrJ3lHK8u0lZO8opa6xGTMY3S+eqSf1Ztb4NE5OTzimqaIdqWtsovxgg+bui/iZwl0OU9fYxNrd5SzLK2HpthJW7iqlvrGZUf3imDG2P2PS4kmJiyS5VwS9YyOIiTi+WbLffmYlb27YR94vZ2quvogfBfU8dzl6kWGhTB6SzOQhyXz3/OFU1Dbw6po9/GNVPg+8s/Uz7eOjwqhvaqbZQb/4KC7MTGXmuH5MzEjqVFi/uWEfAOUHG7rtl9IiwUzh3kPFR4Vz7ZRBXDtlEOUHG9hWXMWBqnoO1NRTXFlHYUUtUeGhmEFuYRVPL93J4x9tp198FLMnpnHlpHSG9Y3r8H32V9Up3EU8oHAXEqLDO7zitrK2gUWbi3ht3R4e+3A7j76fR+9eLUsvpCVGc+7IvsyakEZs5OEfqeKqOoandvyfgIj4l8JdOiUuKpzLJg7gsokDKK6s47V1e8gpqmJv2UG2FlaycFMhv35zM1+bMohrJg9s/bn9VfUeVi3Scync5ailxEVy4xlDWrcPLaT2pw/yeOT9bTzy/rbWY/sr64769T/O3c+QlF70T4j2S70iPZEWE5fjdmghtT9+fRJL7j6P80elEh7a8qXrtqO8g1VTs+MbT35y2AJqInL0NHIXv0pLjOax61tmad31wlpezM5n3IAELshMZfWuMnpFhjImLYGE6Pavmt1XUUttQzOLPy2itqGpw2WURaR9CnfpMvfMHMWyvBLm/n09/H39YccuHZ/GnReOYEifXoft31VSA0BNfRMfbC3mojH9Tli9IsFEp2Wky/SJjWThnWfzyNdP4fxRffndnAlcPTkDgDfW7+WqR5eyt/wgz63Yxf+8tomymnp2HagGIDzUWufKi8jR0xWqcsJV1Dawt6yWK/748WF30+oXH0ViTDg7SqqZMbY/72wuZOWPL9R9ZkXa6OwVqvpXIydcfFQ4I/vF8ei1k8hIjubrUwby7M2nMSYtnm3FVfzXRSOZNT6NytpG3tlcyEOLcrjn7+tYuq3E69JFAoZG7tKtNDY1ExYaQlOz4+zfLKag7OBhx2eO68cvLx9HRFgIL63MJzU+ii/pvLz0IFpbRgJSWGjLL5OhIcbPLx/Lbc+s4sqsdH44czSPf7SdB9/Zyjubi2hoam69V+4vLx/HNacN/IJXFel5NHKXbq2p2RHaZqGyDQXlPP/JbnrHRjA+I5H57+extbCSZT88n/BQnWWU4KeRuwSF0CNWoBw7IIGxAxJat5ubHTc9mc1bG/dxyclpJ7o8kW5LQx0JaOeMSGFY31juf3srjU3NXpcj0m0o3CWghYWG8P0vjSRvfzV/W7HL63JEug2FuwS8izJTOf2k3vzmrS0U+e4dK9LTKdwl4JkZv7h8HHWNzfzstU1elyPSLXQq3M1supltMbNcM5vbzvEbzKzYzNb4Hjf7v1SRzzekTy++M20Yr6/by/tbi70uR8RzHYa7mYUC84AZQCZwtZllttP0eefcBN/jMT/XKdKhW6cNZWhKL+56YQ2rd5V6XY6Ipzozcp8M5Drn8pxz9cBzwOyuLUvk6EWGhTL/2ixCQ4zLH/6YS37/IUty93tdlognOhPuA4DdbbbzffuOdIWZrTOzl8wso70XMrNbzCzbzLKLi/Wrs/jfsL6xvP29c/jvSzOprmviuidW8MyynV6XJXLC+esL1X8Cg51zJwMLgSfba+Scm++cy3LOZaWkpPjprUUOlxATzg1nDOGf/3Em54xI4cevbODnr22irrHJ69JETpjOhHsB0HYknu7b18o5V+KcO3SzzMeASf4pT+TYxUaGMf/aSVw3dRCPfbSdy+Z9zJ4jFiITCVadCfdPgOFmNsTMIoA5wIK2Dcysf5vNWYBugCndQlhoCPfNHsvj12eRf6CG2fOWsEpftkoP0GG4O+cagduBt2gJ7ReccxvN7D4zm+Vr9l0z22hma4HvAjd0VcEix+L80am8fNvpxESEcv3jK9hQUN5uO+ccDVrGQIKAVoWUHmVP2UGufGQpNfWNvPCtqQxPjWs9Vt/YzJf/uITK2kYW3zWNkCMWLRPpDrQqpEg70hKjefbm07jy0aVc/aflnDsyhV0HavjqqRmkJ8WwoaACgC2FlYzuH+9xtSLHTssPSI8zuE8vnvrGZMzglTUFLN9+gD+8m8uHOf+enrs8T7f0k8Cmkbv0SKP7x/PR3efS2OR4dc0efviP9fz+3VwykqM5WN/Epr0VXpcoclw0cpceKzIslF6RYcwc9+97sD741QkM6xtLTlGVh5WJHD+N3KXHS4yJ4D8vGEFCdBiTBiUzIjWOf6wqwDmHmb5UlcCkcBcB7rhgeOvz4X1jqaxrZF9FLf0Tottt75zjw5z99I6NYExaQrttRLykcBc5wrC+LdMjcwqr2g333KJKvv3MKnKKqjCDN+84i1H9NLNGuhedcxc5wvDUWAB+/vombn4ym/sXbqW6rhGA8poGbnl6JaU19dw9fRQRoSH86YPtXpYr0i6N3EWO0Cc2koTocLYWVlFZ28g7mwt5eWU+V0xK56Xs3RRX1fHkjZM5fVgf9pUf5K8rdnH39JH0jY/yunSRVhq5i7Tj0Wsn8Y0zhrDwznN48dapxEWF8dCiHBJjInj+W1M5fVgfAL42ZRANTY53Py3yuGKRw2nkLtKOKUN7M2VobwBOHZzMm3ecRVlNA4kx4YfNoBneN5Y+sRGs2H6AOZMHelWuyGco3EU6wcxI6hXR7v6sQclk79RKk9K96LSMyHEaOyCeXQdqqKxt8LoUkVYKd5HjdGiBsYcW5VCgm4FIN6FwFzlO49ITCAsx/vThdn75xuH3qdlQUE5JVd3n/KRI11G4ixynvnFRvP+Dc5lzagavr9vLkx/vAKCxqZlLfv8Rc+Yv87ZA6ZEU7iJ+MCAxmntmjmZoSi8eWpRDQ1Mz2/dXA2gRMvGEwl3ETxKiw/nJJZmUVNczb3HuYcsGe3XHM+m5FO4ifjRtRAoXZqby9NKdrN5V1rp/X0Wth1VJT6RwF/EjM+PS8WmUVNfzF9+5d4DSak2TlBNL4S7iZ+eN6kuviFAAsgYlAVB+UOEuJ5bCXcTPYiPD+NUVJ3PlpHT+88IRAFToAic5wbT8gEgXmDU+jVnj09h9oAbQyF1OPI3cRbpQfHQ4ABVtwn1v+UF+8NJaDtY3eVWW9AAKd5EuFBcZhtnh4f7rNz/lhex8LRMsXUrhLtKFQkKMuMgwKmobW/eV1bQE/Y6Saq/Kkh5A4S7SxRJiwnllTQHL8kqAf4f62t1lX/RjIsdF4S7SxUamxlNW08Cc+ct4fd1edpa0fMn63tZiymrqPa5OgpXCXaSLzb92EovuOoewEOP37+YA8OOLR9PY1Mzcl9fT3KylCcT/OhXuZjbdzLaYWa6Zzf2CdleYmTOzLP+VKBLYQkKMk1JimZCRyKf7KgkxuDIrgx/OHM2/Nu7jwUU5XpcoQajDcDezUGAeMAPIBK42s8x22sUBdwDL/V2kSDA4d1RfAGaM609CdDg3nTmEWePTmLc4l5r6f3/hunpXKf/14lo2t1l4TORodWbkPhnIdc7lOefqgeeA2e20+x/gfwGtkCTSjm+fcxKPXZfFLy4bC7SsQ3P5xAE0NTvW7i4HWlaP/OmCjby0Mp9H3t/mZbkS4DoT7gOA3W228337WpnZKUCGc+71L3ohM7vFzLLNLLu4uPioixUJZCEhxgWZqSTG/PtG2xMHJgLwzPKdNDc79pbXsi6/Jeg37dHIXY7dcX+hamYhwP3AXR21dc7Nd85lOeeyUlJSjvetRQJeYkwE3zp7KK+v28tPXt3QGuhThiazrbhKV7HKMevM2jIFQEab7XTfvkPigLHAe2YG0A9YYGaznHPZ/ipUJFjNnTGKyrpGnl2+i6XbWubCX3PaIJblHWDxliJmjuvvcYUSiDozcv8EGG5mQ8wsApgDLDh00DlX7pzr45wb7JwbDCwDFOwinWRm/OKysYxPTyBvfzVpCVFcPK4/6UnRPL10p9flSYDqMNydc43A7cBbwGbgBefcRjO7z8xmdXWBIj2BmfG7OROZNjKFB+dMJDTEuOa0gSzNK9GsGTkm5tW9HbOyslx2tgb3Ip+ntLqeab99j4HJMTx2fRap8VFelyTdgJmtdM51eC2RrlAV6aaSekXw2yvHk1tUxew/LKFQ92GVo6BwF+nGLsxM5cVbp1J2sJ5fvbHZ63IkgCjcRbq5sQMSuG7qYBas3UNecZXX5UiAULiLBIBvnjWUiLAQ/vBubus+LTgmX0ThLhIAUuIi+fppg3hlTQEb95Rz5/NrmPbb96ht0EVO0j6Fu0iAuO3cYST3iuTihz7i76sL2HWghve26FZ90j6Fu0iASO4VwbM3n8bF4/rzH+cNo39CFA8tyqWxqdnr0qQb6szyAyLSTYzsF8e8r50CQGb/eL797CqeXLqTm84c4nFl0t1o5C4SoKaP7UfWoCRezN7dcWPpcRTuIgHKrGUJ4U/3VeoCJ/kMhbtIADtnRMvS2e9v1f0R5HAKd5EANqpfHH3jInnio+2s2H7A63KkG1G4iwQwM+OWs4fy6b5Kvjp/KUty93tdknQTCneRAHfzWUNZ/sPzGZAYzS9e36ypkQIo3EWCQmp8FHNnjGLT3goeWpTjdTnSDSjcRYLEJSencfG4/jyxZAd7yw96XY54TOEuEkT+88IRAFzx8MeaHtnDKdxFgsiwvrH85cZT2VNeyz9WF3T8AxK0FO4iQSZrcDJj0uJ5MXs327T+e4+lcBcJQnddNIJdB2r40gMf8Ms3NrO1sNLrkuQEU7iLBKHzRqXywQ/O5fRhfZj/QR7TH/yANbvLvC5LTiCFu0iQ6p8QzRPXZ/G3b04hIiyEeYtzcU53b+opFO4iQSwsNISpJ/XmP84bzsJNhbygFSR7DIW7SA9w27STOHVwEvf9cxMfb9MSBT2Bwl2kBzAz/nDNKaQlRnPd4yt4aukOr0uSLqZwF+khUuOjeOnW05k2MoV7X92oZYKDnMJdpAdJiAnnwTkTSe4VwfVPrGBDQbnXJUkXUbiL9DCxkWH8+YZTAVi6rcTjaqSrKNxFeqDxGYmkJ0Xz0sp86hu1RHAw6lS4m9l0M9tiZrlmNred47ea2XozW2NmH5lZpv9LFRF/unJSBlsKK/nTh3lelyJdoMNwN7NQYB4wA8gErm4nvP/qnBvnnJsA/Aa43++Viohf3XHBcM4Y1pu/Lt+li5uCUGdG7pOBXOdcnnOuHngOmN22gXOuos1mL0CfFJEAcOnJaRSUHSSnSAuMBZvOhPsAoO1lbfm+fYcxs++Y2TZaRu7fbe+FzOwWM8s2s+ziYk3DEvHamcP7APCBpkUGHb99oeqcm+ecOwm4G/jx57SZ75zLcs5lpaSk+OutReQYpSfFMDSlFx/m6KrVYNOZcC8AMtpsp/v2fZ7ngMuOpygROXHOHp7CsrwSPswp5oY/ryBPa8AHhc6E+yfAcDMbYmYRwBxgQdsGZja8zebFgO7QKxIgvnHGEJJiIrj28RW8t6WYuS+v97ok8YMOw9051wjcDrwFbAZecM5tNLP7zGyWr9ntZrbRzNYAdwLXd1nFIuJXA3vH8OKtUxnSpxcAm/dVaPZMEDCv/hKzsrJcdna2J+8tIp/V1Ox47MM8fvXmp6z88QX0jo30uiRph5mtdM5lddROV6iKCAChIcaI1DgAthVXe1yNHC+Fu4i0GprScmrmqkeX0tysUzOBTOEuIq0GJsdwlm/ue65mzQQ0hbuItDIz7ps9FoDf/GsLf3g3h10lNazaVUpjkxYYCyRhXhcgIt3L4N4xnJyewDubC3lncyG/fXsrANPH9OOPXz8FM/O4QukMhbuIHMbMeO6WKWzeW0lEaAgLN+1jR0kNC9bu4aPc/Zw1XFeXBwKFu4h8RkxEGJMGJQEwLj2BusYmsncc4IGFWzlzWB+N3gOAzrmLSIciw0L5znnDWLWrTPdeDRAKdxHplCsnZTAgMZoHFm7VFawBQOEuIp0SERbCd88fxtr8cl5ame91OdIBhbuIdNpXJmUwZWgy9766kdyiSq/LkS+gcBeRTgsNMX43ZyIxEaHc+swqSqvrvS5JPofCXUSOSmp8FH+45hR2H6jha48tp6ii1uuSpB0KdxE5alNP6s3867LYVlzFT17d4HU50g6Fu4gck3NGpHDd1EEs2lzE/qo6r8uRIyjcReSYXZWVQWOz45XVX3TnTfGCrlAVkWM2PDWOSYOSeOT9bWwrrmLLvkr+dssUIsNCvS6tx9PIXUSOyy8uH8v+qnr+tmI3q3aV8c+1e70uSVC4i8hxGtUvnpS4llvyxUeFaXmCbkKnZUTkuP3z9jMpP9jAAwu3si6/zOtyBI3cRcQP+iVEMbJfHCdnJLCzpIYDurjJcwp3EfGbyYOTAXh1TQG7D9R4XE3PpnAXEb85OT2RqPAQfvbPTZz1m8V8nLufyx9ewpvr9SXriaZwFxG/iQgL4aqsjNbtee/lsnpXGY98kOdhVT2Twl1E/Oqnl47h+18aCcCS3BIA1u4uI79Up2lOJIW7iPhVaIhx4xmDSYoJB+Cpb0wmxODZ5bs8rqxn0VRIEfG7mIgwFt01jQPVdQzrG8eUob35KGc/d0/3urKeQyN3EekSyb0iGNY3DoCxAxLYUlhJQ1Ozx1X1HAp3Eelymf3jqW9sZltxldel9BidCnczm25mW8ws18zmtnP8TjPbZGbrzGyRmQ3yf6kiEqgmDUoCYMGaPazdrStYT4QOw93MQoF5wAwgE7jazDKPaLYayHLOnQy8BPzG34WKSODKSI5hTFo8D7+3jdnzllBd1+h1SUGvMyP3yUCucy7POVcPPAfMbtvAObfYOXdontMyIN2/ZYpIoPvppWNan3+Yo8XFulpnwn0AsLvNdr5v3+e5CXizvQNmdouZZZtZdnGx/nJFepLJQ5LJ+cUM+idEcffL63n300KvSwpqfv1C1cy+DmQB/9fecefcfOdclnMuKyUlxZ9vLSIBIDw0hMevP5WmZsev3vjU63KCWmfCvQDIaLOd7tt3GDO7APgRMMs5pxsqiki7MtPiuXvGKHKKqli584DX5QStzoT7J8BwMxtiZhHAHGBB2wZmNhF4lJZgL/J/mSISTL48cQD94qO499WNNDU7r8sJSh2Gu3OuEbgdeAvYDLzgnNtoZveZ2Sxfs/8DYoEXzWyNmS34nJcTEaFXZBg/uSSTjXsq+H9vb8E5Bby/dWr5AefcG8AbR+y7t83zC/xcl4gEuZnj+jFtZAoPv7eN5F4R3HzWUK9LCiq6QlVEPGFmPHrtJIb1jeXJpTuorG3wuqSgonAXEc9EhoXy35eOYW9ZLZc//DG5RZVelxQ0FO4i4qkzh/fhqZsmU1ZTz9ceW05hRa3XJQUFhbuIeO70k/rw9E2nUVnbyC1PZVPb0OR1SQFP4S4i3cLo/vH8bs5E1hWU84OX1mkGzXFSuItIt3FhZirf/9JIFqzdw7zFuV6XE9B0JyYR6Va+fc5J5BRW8du3t5KWGM2XT9E6hMdC4S4i3YqZ8esrxlFUWcv3X1pHQnQ4549O9bqsgKPTMiLS7USGhfLotVmMSYvntmdXkb1Da9AcLYW7iHRLsZFh/PmGUxmQGM1NT2ZrDvxRUriLSLfVOzaSJ78xmfDQEL7xl2xKq+u9LilgKNxFpFvLSI5h/nWT2FdRyzc1B77TFO4i0u2dMjCJB66awMpdpXz3b6u1THAnKNxFJCBcfHJ/7r0kk7c3FXLP39fR2NTsdUndmqZCikjAuPGMIZTWNPDQohwOVDcw/9pJhISY12V1Sxq5i0hAufPCEfz44tG8s7mQH72ynrpGnYNvj0buIhJwbjpzCPur6nnk/W18mLOfF2+dSv+EaK/L6lY0cheRgGNmzJ0xij/fcColVfXc/GQ2+8q1VHBbCncRCVjnjurLvK9NZMf+amb94SPW7C7zuqRuQ+EuIgHtvFGpvHzb6USEhXDVo0t5dU2B1yV1Cwp3EQl4o/rF8+p3zmBCRiJ3PLeG3/zrU5p7+Fx4hbuIBIXesZE8c9NpXD05g4ff28a3nllJdV2j12V5RuEuIkEjIiyEX14+jv++NJNFmwuZ8bsPeXb5Tq/L8oTCXUSCiplxwxlD+PONk0mKCedH/9jQI8/DK9xFJCidMyKFF26dyvj0BO54bg03P/kJO0uqvS7rhFG4i0jQigwL5flvTeUH00eyLO8AFz7wAQ8tyukRV7Uq3EUkqEWFh3LbtGEsuuscLsxM5f6FW5nxuw9ZsT247+6kcBeRHiE1Pop515zCX248lfrGZq56dCl3Pr+Gj3P3e11al+hUuJvZdDPbYma5Zja3neNnm9kqM2s0s6/4v0wREf+YNrIvb33vbG4+cwivrCngmseW88rq4PvCtcNwN7NQYB4wA8gErjazzCOa7QJuAP7q7wJFRPytV2QYP74kkw0/+xKTByfzvefX8OWHl7D40yKcC46Lnzozcp8M5Drn8pxz9cBzwOy2DZxzO5xz6wCtni8iASMmIozHbsjiRzNHU1xVx41/+YSvzl8WFGvUdCbcBwC722zn+/aJiAS8+Khwvnn2UN69axr/M3sMecVVXDZvCbf/dVVAT508oV+omtktZpZtZtnFxcUn8q1FRL5QeGgI104dzHvfP5fvnjeMRZuLuOD+9/nlG5spqgi85YQ7E+4FQEab7XTfvqPmnJvvnMtyzmWlpKQcy0uIiHSp2Mgw7rxoJO99fxqXTRjA/A/ymPrrd/nW09kBNbOmM3di+gQYbmZDaAn1OcA1XVqViIjHUuOj+L8rx3PbucN4bsUuXlyZz1sbC7lgdF+unTqYs4b16db3b7XOfDNsZjOBB4FQ4Ann3C/M7D7MryOdAAAFc0lEQVQg2zm3wMxOBf4BJAG1wD7n3Jgves2srCyXnZ193B0QETkR6hqbeOS9PJ5auoOS6noG9Y7hmskDuTIrg+ReESesDjNb6ZzL6rCdV9N+FO4iEojqGpv414Z9PLtsFyt2HCAiLITx6QnMGp/GtVMHd/n7K9xFRLrY1sJK/rZiF8vyDrB5bwURYSGcPbwPP5w5mqEpsV3yngp3EZETpKGpmaeW7mRbcRWvrC6gpr6JAYnRTBnam+lj+3HeqL6E+un8vMJdRMQDRZW1vLQyn40FFXyUu5/ygw2kxkdyxSnpXJWVweA+vY7r9RXuIiIea2xq5u1NhbyYvZvFW1qu7UlLiOLuGaOYPeHYrgXtbLh3ZiqkiIgcg7DQEGaO68/Mcf3ZVVLD4i1FrNxZSkpcZJe/t0buIiIBpLMjd63nLiIShBTuIiJBSOEuIhKEFO4iIkFI4S4iEoQU7iIiQUjhLiIShBTuIiJByLOLmMysGNh5jD/eBwicW6IcPfUvsAV7/yD4+9id+zfIOdfhrew8C/fjYWbZnblCK1Cpf4Et2PsHwd/HYOifTsuIiAQhhbuISBAK1HCf73UBXUz9C2zB3j8I/j4GfP8C8py7iIh8sUAduYuIyBcIuHA3s+lmtsXMcs1srtf1HAsze8LMisxsQ5t9yWa20MxyfH8m+fabmT3k6+86MzvFu8o7x8wyzGyxmW0ys41mdodvf1D00cyizGyFma319e9nvv1DzGy5rx/Pm1mEb3+kbzvXd3ywl/V3lpmFmtlqM3vNtx00/TOzHWa23szWmFm2b19QfD4PCahwN7NQYB4wA8gErjazTG+rOiZ/AaYfsW8usMg5NxxY5NuGlr4O9z1uAf54gmo8Ho3AXc65TGAK8B3f31Ow9LEOOM85Nx6YAEw3synA/wIPOOeGAaXATb72NwGlvv0P+NoFgjuAzW22g61/5zrnJrSZ8hgsn88WzrmAeQBTgbfabN8D3ON1XcfYl8HAhjbbW4D+vuf9gS2+548CV7fXLlAewKvAhcHYRyAGWAWcRstFL2G+/a2fVeAtYKrveZivnXldewf9Sqcl4M4DXgMsyPq3A+hzxL6g+nwG1MgdGADsbrOd79sXDFKdc3t9z/cBqb7nAd1n36/oE4HlBFEffacs1gBFwEJgG1DmnGv0NWnbh9b++Y6XA71PbMVH7UHgB0Czb7s3wdU/B7xtZivN7BbfvqD5fIJukN0tOeecmQX8NCYziwVeBr7nnKsws9Zjgd5H51wTMMHMEoF/AKM8LslvzOwSoMg5t9LMpnldTxc50zlXYGZ9gYVm9mnbg4H++YQAO+cOFAAZbbbTffuCQaGZ9Qfw/Vnk2x+QfTazcFqC/Vnn3N99u4OqjwDOuTJgMS2nKRLN7NCAqW0fWvvnO54AlJzgUo/GGcAsM9sBPEfLqZnfETz9wzlX4PuziJb/nCcTZJ/PQAv3T4Dhvm/tI4A5wAKPa/KXBcD1vufX03Ke+tD+63zf2E8Bytv86tgtWcsQ/XFgs3Pu/jaHgqKPZpbiG7FjZtG0fJ+wmZaQ/4qv2ZH9O9TvrwDvOt/J2+7IOXePcy7dOTeYln9j7zrnvkaQ9M/MeplZ3KHnwEXABoLk89nK65P+x/BFyExgKy3nOH/kdT3H2Ie/AXuBBlrO391EyznKRUAO8A6Q7GtrtMwQ2gasB7K8rr8T/TuTlnOa64A1vsfMYOkjcDKw2te/DcC9vv1DgRVALvAiEOnbH+XbzvUdH+p1H46ir9OA14Kpf75+rPU9Nh7KkWD5fB566ApVEZEgFGinZUREpBMU7iIiQUjhLiIShBTuIiJBSOEuIhKEFO4iIkFI4S4iEoQU7iIiQej/A2t6F099HdYBAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6b44d915d538178fc01462f47c9c84995fbbc316"
      },
      "cell_type": "code",
      "source": "def train(epoch):\n    for idx, batch_data in enumerate(dataloader):\n        x, target=batch_data['image'].float().cuda(),batch_data['label'].float().cuda()\n\n\n        optimizer.zero_grad()\n        output = net(x)\n        output.squeeze_(1)\n#         print(target.size())\n        ran=np.random.randint(0,10,1)[0]\n        \n        temp=torch.sigmoid(output[ran]).cpu().detach().numpy()\n        temp[temp>0.5]=1\n        temp[temp<0.5]=0\n#         print(temp)\n        \n        print('pred')\n\n        \n        plt.imshow(temp[1])\n        plt.show()\n        \n        plt.imshow(target[ran].cpu().detach().numpy())\n        plt.show()\n#         print(target[ran].cpu().detach().numpy())\n\n        bce_loss = criterion(output, target.long())\n\n\n#         dice_loss = dice(output, target)\n#         loss = bce_loss #+ dice_loss \n#         loss.backward()\n#         optimizer.step()\n        \n        \n        \n#         print('Epoch {}, loss {}, bce {}, dice {}'.format(\n#             idx, loss.item(), bce_loss.item(), dice_loss.item()))\n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8b0bff2416364d132864a9a7fdee4a62ea430c31"
      },
      "cell_type": "code",
      "source": "for epoch in range(10):train(epoch)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "720cb417c732c143cdc76de1bf871e5c76162908"
      },
      "cell_type": "code",
      "source": "#with bce+dice\nfor i in range(1000):train()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a50754678328b80b22002a05ed6705c21e719977"
      },
      "cell_type": "code",
      "source": "def twod_one_hot(targets):    # one hot encodes 3D block to 5 channels with each channel as only one class\n    targets_extend=targets.clone().long() # long needed\n    targets_extend.unsqueeze_(1) # convert to Nx1xHxW\n    one_hot = torch.FloatTensor(targets_extend.size(0), 1, targets_extend.size(2)).zero_() # add zero axis\n    print(one_hot.size(),one_hot)\n    one_hot.scatter_(1,targets_extend ,one_hot) # scatter\n    return one_hot",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e1257becf0cc72af8247f9a777e37376946dccbb"
      },
      "cell_type": "code",
      "source": "twod_one_hot(torch.tensor(tar))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ea2f122d858008b4e211f928d3f2224308e5d737"
      },
      "cell_type": "code",
      "source": "target=plt.imread(\"../input/train/images/aabb4516d1.png\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f7a031df4e91ea8b750b33b01049e5227ceac8ea"
      },
      "cell_type": "code",
      "source": "np.shape(tar)\ntarget=np.expand_dims(target,0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1573804ee8c9fc5dc5e7456ba267528222cfba6c"
      },
      "cell_type": "code",
      "source": "smooth=.001\n    \ndummy=np.zeros([batch_size,2,101,101]) # create dummy to one hot encode target\ndummy[:,0,:,:][target[==0]=1 # background class is 0\ndummy[:,1,:,:][target==1]=1 # salt class is 1 \n\nplt.imshow(dummy[0,0,:,:])\nplt.show()\n\nplt.imshow(dummy[0,1,:,:])\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c7f189fba66aaa36fd89c4a6fcc7e96a51745790"
      },
      "cell_type": "code",
      "source": "np.shape(dummy)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f82046e0e9fba5f0e39947c520fda633892fc212"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}